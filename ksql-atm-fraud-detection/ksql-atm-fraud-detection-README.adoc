= ATM Fraud Detection with Kafka and KSQL - Hands on Guide
Robin Moffatt <robin@confluent.io>
v1.00, October 9, 2018

== Running the test rig

=== Setup

[source,bash]
----
git clone https://github.com/confluentinc/demo-scene.git
cd ksql-atm-fraud-detection
docker-compose up -d
----

This brings up the stack, and also loads the necessary Kafka Connect, Elasticsearch, and Kibana configuration. 

To launch the ATM data generator: 

[source,bash]
----
git clone https://github.com/rmoff/gess.git
cd gess
python scripts/gess-main.py
----

This emits the transactions on UDP - to stream these into a Kafka topic, run

[source,bash]
----
nc -v -u -l 6900 | \
  docker run --interactive --rm --network ksql-atm-fraud-detection_default confluentinc/cp-kafkacat \
  kafkacat -b kafka:29092 -P -t atm_txns_gess
----

Inspect source transactions: 

[source,sql]
----
PRINT 'atm_txns_gess' FROM BEGINNING;
----

Register the topic as a KSQL stream: 

[source,sql]
----
CREATE STREAM ATM_TXNS_GESS (account_id VARCHAR, \
                            atm VARCHAR, \
                            location STRUCT<lon DOUBLE, \
                                            lat DOUBLE>, \
                            amount INT, \
                            timestamp VARCHAR, \
                            transaction_id VARCHAR) \
            WITH (KAFKA_TOPIC='atm_txns_gess', \
            VALUE_FORMAT='JSON', \
            TIMESTAMP='timestamp', \
            TIMESTAMP_FORMAT='yyyy-MM-dd HH:mm:ss X');
----

Query the stream: 

[source,sql]
----
ksql> SELECT TIMESTAMPTOSTRING(ROWTIME, 'yyyy-MM-dd HH:mm:ss Z'), ACCOUNT_ID, ATM, AMOUNT FROM ATM_TXNS_GESS LIMIT 5;

2018-11-23 11:57:45 +0000 | a136 | ATM : 48930597 | 200
2018-11-23 11:57:46 +0000 | a552 | ATM : 1626440972 | 300
2018-11-23 11:57:47 +0000 | a250 | Barclays | 400
2018-11-23 11:57:47 +0000 | a327 | ATM : 1182516742 | 300
2018-11-23 11:57:48 +0000 | a973 | ATM : 5920382950 | 400
----

Create a clone of the stream: 

[source,sql]
----
CREATE STREAM ATM_TXNS_GESS_02 WITH (PARTITIONS=1) AS SELECT * FROM ATM_TXNS_GESS;
----

Join the stream (two in practice, but logically still just a single Kafka topic): 

[source,sql]
----
SELECT S1.ACCOUNT_ID, \
        TIMESTAMPTOSTRING(S1.ROWTIME, 'yyyy-MM-dd HH:mm:ss'), TIMESTAMPTOSTRING(S2.ROWTIME, 'HH:mm:ss'), \
        S1.ATM, S2.ATM, \
        S1.TRANSACTION_ID ,S2.TRANSACTION_ID \
FROM   ATM_TXNS_GESS S1 \
       INNER JOIN ATM_TXNS_GESS_02 S2 \
        WITHIN 10 MINUTES \
        ON S1.ACCOUNT_ID = S2.ACCOUNT_ID;
----

Filter out direct matches to self and exclude those in the same location: 

[source,sql]
----
SELECT S1.ACCOUNT_ID, \
        TIMESTAMPTOSTRING(S1.ROWTIME, 'yyyy-MM-dd HH:mm:ss'), TIMESTAMPTOSTRING(S2.ROWTIME, 'HH:mm:ss'), \
        S1.ATM, S2.ATM, \
        S1.TRANSACTION_ID ,S2.TRANSACTION_ID \
FROM   ATM_TXNS_GESS S1 \
       INNER JOIN ATM_TXNS_GESS_02 S2 \
        WITHIN 10 MINUTES \
        ON S1.ACCOUNT_ID = S2.ACCOUNT_ID \
WHERE   S1.TRANSACTION_ID != S2.TRANSACTION_ID \
  AND   (S1.location->lat != S2.location->lat OR \
         S1.location->lon != S2.location->lon) \
LIMIT 20;
----


Join only to future-dated events: 

[source,sql]
----
SELECT S1.ACCOUNT_ID, \
        TIMESTAMPTOSTRING(S1.ROWTIME, 'yyyy-MM-dd HH:mm:ss'), TIMESTAMPTOSTRING(S2.ROWTIME, 'HH:mm:ss'), \
        S1.ATM, S2.ATM \
FROM   ATM_TXNS_GESS S1 \
       INNER JOIN ATM_TXNS_GESS_02 S2 \
        WITHIN (0 MINUTES, 10 MINUTES) \
        ON S1.ACCOUNT_ID = S2.ACCOUNT_ID \
WHERE   S1.TRANSACTION_ID != S2.TRANSACTION_ID \
  AND   (S1.location->lat != S2.location->lat OR \
         S1.location->lon != S2.location->lon) \
  AND   S2.ROWTIME != S1.ROWTIME;

----

Derive distance between ATMs: 

Calculate time between events: 

Calculate required speed: 

Persist as a new stream: 


View the resulting transactions: 

[source,sql]
----
SELECT ACCOUNT_ID, \
        TIMESTAMPTOSTRING(S1_TIMESTAMP, 'yyyy-MM-dd HH:mm:ss'), TIMESTAMPTOSTRING(S2_TIMESTAMP, 'HH:mm:ss'), \
        S1_ATM, S2_ATM, \
        DISTANCE_BETWEEN_TXN_KM, MINUTES_DIFFERENCE \
FROM ATM_POSSIBLE_FRAUD;  
----

++++
<script src="https://asciinema.org/a/xuzkbePj2N9fsAZZew0eJUjCW.js" id="asciicast-xuzkbePj2N9fsAZZew0eJUjCW" async></script>
++++

Add in Customer data: 


View enriched data: 

== Sending test messages

Send a couple of test messages to the ATM topic, using `kafkacat`: 

[source,bash]
----
SELECT ACCOUNT_ID, CUSTOMER_NAME, CUSTOMER_PHONE, \
        TIMESTAMPTOSTRING(S1_TIMESTAMP, 'yyyy-MM-dd HH:mm:ss'), TIMESTAMPTOSTRING(S2_TIMESTAMP, 'HH:mm:ss'), \
        S1_ATM, S2_ATM \
FROM ATM_POSSIBLE_FRAUD_ENRICHED;
----

=== Launching KSQL

[source,bash]
----
docker run --network ksql-atm-fraud-detection_default --interactive --tty --rm \
    confluentinc/cp-ksql-cli:5.0.0 \
    http://ksql-server:8088
----

=== Sending more test messages

[source,bash]
----
docker run --interactive --rm --network ksql-atm-fraud-detection_default confluentinc/cp-kafkacat kafkacat -b kafka:29092 -P -t atm_txns << EOF
{"account_id": "ac_02", "atm": "Flying Pig Bistro", "amount": 40, "location": {"lat": "37.766319", "lon": "-122.417422"}, "transaction_id": "03"}
{"account_id": "ac_03", "atm": "Barclays", "amount": 500, "location": {"lat": "33.5522855", "lon": "-120.9797997"}, "transaction_id": "X05"}
EOF
----

=== Finished KSQL statement for processing test messages

[source,sql]
----
include::test_messages.ksql[]
----

