---
version: '3'
services:

  kafka-connect-01:
    image: confluentinc/cp-kafka-connect:${CONFLUENTPLATFORM_VERSION}
    container_name: kafka-connect-01
    # depends_on:
    #   - zookeeper
    #   - kafka
    #   - schema-registry
    ports:
      - 8083:8083
    environment:
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      CONNECT_CUB_KAFKA_TIMEOUT: 300
      CONNECT_BOOTSTRAP_SERVERS: "${CCLOUD_BROKER_HOST}:9092"
      CONNECT_REST_ADVERTISED_HOST_NAME: 'kafka-connect-01'
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: kafka-connect-group-01
      CONNECT_CONFIG_STORAGE_TOPIC: _kafka-connect-group-01-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _kafka-connect-group-01-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _kafka-connect-group-01-status
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: "${CCLOUD_SCHEMA_REGISTRY_URL}"
      CONNECT_KEY_CONVERTER_BASIC_AUTH_CREDENTIALS_SOURCE: "USER_INFO"
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: "${CCLOUD_SCHEMA_REGISTRY_API_KEY}:${CCLOUD_SCHEMA_REGISTRY_API_SECRET}"
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "${CCLOUD_SCHEMA_REGISTRY_URL}"
      CONNECT_VALUE_CONVERTER_BASIC_AUTH_CREDENTIALS_SOURCE: "USER_INFO"
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: "${CCLOUD_SCHEMA_REGISTRY_API_KEY}:${CCLOUD_SCHEMA_REGISTRY_API_SECRET}"
      CONNECT_INTERNAL_KEY_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_INTERNAL_VALUE_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_LOG4J_ROOT_LOGLEVEL: 'INFO'
      CONNECT_LOG4J_LOGGERS: 'org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR'
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: '3'
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: '3'
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: '3'
      CONNECT_PLUGIN_PATH: '/usr/share/java,/usr/share/confluent-hub-components/'
      # External secrets config
      # See https://docs.confluent.io/current/connect/security.html#externalizing-secrets
      CONNECT_CONFIG_PROVIDERS: 'file'
      CONNECT_CONFIG_PROVIDERS_FILE_CLASS: 'org.apache.kafka.common.config.provider.FileConfigProvider'
      # Confluent Cloud config
      CONNECT_REQUEST_TIMEOUT_MS: "20000"
      CONNECT_RETRY_BACKOFF_MS: "500"
      CONNECT_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "https"
      CONNECT_SASL_MECHANISM: "PLAIN"
      CONNECT_SECURITY_PROTOCOL: "SASL_SSL"
      CONNECT_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${CCLOUD_API_KEY}\" password=\"${CCLOUD_API_SECRET}\";"
      #
      CONNECT_CONSUMER_SECURITY_PROTOCOL: "SASL_SSL"
      CONNECT_CONSUMER_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "https"
      CONNECT_CONSUMER_SASL_MECHANISM: "PLAIN"
      CONNECT_CONSUMER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${CCLOUD_API_KEY}\" password=\"${CCLOUD_API_SECRET}\";"
      CONNECT_CONSUMER_REQUEST_TIMEOUT_MS: "20000"
      CONNECT_CONSUMER_RETRY_BACKOFF_MS: "500"
      #
      CONNECT_PRODUCER_SECURITY_PROTOCOL: "SASL_SSL"
      CONNECT_PRODUCER_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "https"
      CONNECT_PRODUCER_SASL_MECHANISM: "PLAIN"
      CONNECT_PRODUCER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${CCLOUD_API_KEY}\" password=\"${CCLOUD_API_SECRET}\";"
      CONNECT_PRODUCER_REQUEST_TIMEOUT_MS: "20000"
      CONNECT_PRODUCER_RETRY_BACKOFF_MS: "500"
    command: 
      # In the command section, $ are replaced with $$ to avoid the error 'Invalid interpolation format for "command" option'
      - bash 
      - -c 
      - |
        echo "Installing connector plugins"
        confluent-hub install --no-prompt confluentinc/kafka-connect-mqtt:1.2.3
        #
        echo "Launching Kafka Connect worker"
        /etc/confluent/docker/run & 
        #
        sleep infinity

  # elasticsearch:
  #   image: docker.elastic.co/elasticsearch/elasticsearch:6.7.0
  #   container_name: elasticsearch
  #   ports:
  #     - 9200:9200
  #   environment:
  #     xpack.security.enabled: "false"
  #     ES_JAVA_OPTS: "-Xms1g -Xmx1g"
  #   command: 
  #     - bash 
  #     - -c 
  #     - |
  #       /usr/local/bin/docker-entrypoint.sh & 
  #       echo "Waiting for Elasticsearch to start ⏳"
  #       while : ; do
  #         curl_status=$$(curl -s -o /dev/null -w %{http_code} http://localhost:9200/)
  #         echo -e $$(date) " Elasticsearch listener HTTP state: " $$curl_status " (waiting for 200)"
  #         if [ $$curl_status -eq 200 ] ; then
  #           break
  #         fi
  #         sleep 5 
  #       done
  #       echo -e "\n--\n+> Creating Elasticsearch dynamic mapping"
  #       curl -XPUT "http://localhost:9200/_template/kafkaconnect/" -H 'Content-Type: application/json' -d'
  #       {
  #           "index_patterns": "*",
  #           "settings": {
  #               "number_of_shards": 1,
  #               "number_of_replicas": 0
  #           },
  #           "mappings": {
  #               "dynamic_templates": [
  #                   {
  #                       "dates": {
  #                           "match": "*_TS",
  #                           "mapping": {
  #                               "type": "date"
  #                           }
  #                       }
  #                   },
  #                   {
  #                       "heights": {
  #                           "match": "HEIGHT",
  #                           "mapping": {
  #                               "type": "float"
  #                           }
  #                       }
  #                   },
  #                   {
  #                       "locations": {
  #                           "match": "LOCATION",
  #                           "mapping": {
  #                               "type": "geo_point"
  #                           }
  #                       }
  #                   }
  #               ]
  #           }
  #       }'
  #       sleep infinity



  # kibana:
  #   image: docker.elastic.co/kibana/kibana:6.7.0
  #   container_name: kibana
  #   depends_on:
  #     - elasticsearch
  #   ports:
  #     - 5601:5601
  #   environment:
  #     xpack.security.enabled: "false"
  #     discovery.type: "single-node"
  #   command: 
  #     - bash 
  #     - -c 
  #     - |
  #       /usr/local/bin/kibana-docker & 
  #       #
  #       echo "Waiting for Kibana to start ⏳"
  #       while : ; do
  #         curl_status=$$(curl -s -o /dev/null -w %{http_code} http://localhost:5601/api/kibana/settings)
  #         echo -e $$(date) " Kibana listener HTTP state: " $$curl_status " (waiting for 200)"
  #         if [ $$curl_status -eq 200 ] ; then
  #           break
  #         fi
  #         sleep 5 
  #       done
  #       #
  #       echo "Waiting for Kibana API to be available ⏳"
  #       while : ; do
  #         kibana_status=$$(curl -s 'http://localhost:5601/api/kibana/settings')
  #         echo -e $$(date) " Kibana API response: " $$kibana_status
  #         if [ $$kibana_status != "Kibana server is not ready yet" ] ; then
  #           break
  #         fi
  #         sleep 5 
  #       done
  #       #
  #       sleep 60 
  #       echo -e "\n--\n+> Setup Kibana objects"

  #       echo -e "\n--\n+> Opt out of Kibana telemetry"
  #       curl 'http://localhost:5601/api/telemetry/v1/optIn' -H 'kbn-xsrf: nevergonnagiveyouup' -H 'content-type: application/json' -H 'accept: application/json' --data-binary '{"enabled":false}' --compressed

  #       echo -e "\n--\n+> Create Kibana index patterns"
  #       curl -XPOST 'http://localhost:5601/api/saved_objects/index-pattern/runner_location_idx' \
  #           -H 'kbn-xsrf: nevergonnagiveyouup' \
  #           -H 'Content-Type: application/json' \
  #           -d '{"attributes":{"title":"runner_location","timeFieldName":"EVENT_TS"}}'

  #       curl -XPOST 'http://localhost:5601/api/saved_objects/index-pattern/runner_status_idx' \
  #           -H 'kbn-xsrf: nevergonnagiveyouup' \
  #           -H 'Content-Type: application/json' \
  #           -d '{"attributes":{"title":"runner_status","timeFieldName":"EVENT_TS"}}'

  #       echo -e "\n--\n+> Set default Kibana index"
  #       curl -XPOST 'http://localhost:5601/api/kibana/settings' \
  #           -H 'kbn-xsrf: nevergonnagiveyouup' \
  #           -H 'content-type: application/json' \
  #           -d '{"changes":{"defaultIndex":"runner_status_idx"}}'

  #       echo -e "\n--\n+> Import Kibana objects"

  #       sleep infinity
