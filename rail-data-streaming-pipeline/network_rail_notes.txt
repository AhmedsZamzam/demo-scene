NROD
Network Rail Open Data

https://wiki.openraildata.com/index.php?title=About_the_Network_Rail_feeds
https://wiki.openraildata.com/index.php?title=Train_Movements


curl -i -X POST -H "Accept:application/json" \
    -H  "Content-Type:application/json" http://localhost:8083/connectors/ \
    -d '{
  "name": "source-activemq-networkrail-01",
  "config": {
    "connector.class": "io.confluent.connect.activemq.ActiveMQSourceConnector",
    "activemq.url":"tcp://datafeeds.networkrail.co.uk:61618",
    "activemq.username":"NROD_USERNAME",
    "activemq.password":"NROD_PASSWORD",
    "jms.destination.type":"topic",
    "jms.destination.name":"TD_LNE_GN_SIG_AREA",
    "kafka.topic":"networkrail_TD_LNE_GN_SIG_AREA",
    "confluent.license":"",
    "confluent.topic.bootstrap.servers":"kafka:29092",
    "confluent.topic.replication.factor":1
  }
}'


curl -i -X POST -H "Accept:application/json" \
    -H  "Content-Type:application/json" http://localhost:8083/connectors/ \
    -d '{
  "name": "source-activemq-networkrail-02",
  "config": {
    "connector.class": "io.confluent.connect.activemq.ActiveMQSourceConnector",
    "activemq.url":"tcp://datafeeds.networkrail.co.uk:61618",
    "activemq.username":"NROD_USERNAME",
    "activemq.password":"NROD_PASSWORD",
    "jms.destination.type":"topic",
    "jms.destination.name":"TRAIN_MVT_ED_TOC",
    "kafka.topic":"networkrail_TRAIN_MVT_ED_TOC",
    "confluent.license":"",
    "confluent.topic.bootstrap.servers":"kafka:29092",
    "confluent.topic.replication.factor":1
  }
}'


Fails against  61618

org.apache.kafka.connect.errors.ConnectException: Exception thrown while creating connection.
   at io.confluent.connect.jms.BaseJmsSourceTask.start(BaseJmsSourceTask.java:73)
   at org.apache.kafka.connect.runtime.WorkerSourceTask.execute(WorkerSourceTask.java:199)
   at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:175)
   at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:219)
   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
   at java.util.concurrent.FutureTask.run(FutureTask.java:266)
   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
   at java.lang.Thread.run(Thread.java:748)
Caused by: javax.jms.JMSException: Wire format negotiation timeout: peer did not send his wire format.
   at org.apache.activemq.util.JMSExceptionSupport.create(JMSExceptionSupport.java:72)
   at org.apache.activemq.ActiveMQConnection.syncSendPacket(ActiveMQConnection.java:1413)
   at org.apache.activemq.ActiveMQConnection.ensureConnectionInfoSent(ActiveMQConnection.java:1478)
   at org.apache.activemq.ActiveMQConnection.start(ActiveMQConnection.java:527)
   at io.confluent.connect.jms.BaseJmsSourceTask.start(BaseJmsSourceTask.java:71)
   ... 8 more
Caused by: java.io.IOException: Wire format negotiation timeout: peer did not send his wire format.
   at org.apache.activemq.transport.WireFormatNegotiator.oneway(WireFormatNegotiator.java:99)
   at org.apache.activemq.transport.MutexTransport.oneway(MutexTransport.java:68)
   at org.apache.activemq.transport.ResponseCorrelator.asyncRequest(ResponseCorrelator.java:81)
   at org.apache.activemq.transport.ResponseCorrelator.request(ResponseCorrelator.java:86)
   at org.apache.activemq.ActiveMQConnection.syncSendPacket(ActiveMQConnection.java:1388)
   ... 11 more

Same error from activemq-cli



---

try it against 61619


curl -i -X POST -H "Accept:application/json" \
    -H  "Content-Type:application/json" http://localhost:8083/connectors/ \
    -d '{
  "name": "source-activemq-networkrail-01",
  "config": {
    "connector.class": "io.confluent.connect.activemq.ActiveMQSourceConnector",
    "activemq.url":"tcp://datafeeds.networkrail.co.uk:61619",
    "activemq.username":"NROD_USERNAME",
    "activemq.password":"NROD_PASSWORD",
    "jms.destination.type":"topic",
    "jms.destination.name":"TD_LNE_GN_SIG_AREA",
    "kafka.topic":"networkrail_TD_LNE_GN_SIG_AREA",
    "confluent.license":"",
    "confluent.topic.bootstrap.servers":"kafka:29092",
    "confluent.topic.replication.factor":1
  }
}'


This works!

{
  "messageID": "ID:opendata-backend.rockshore.net-38887-1556015157154-11:11706:2:40:48699",
  "messageType": "text",
  "timestamp": 1558388511199,
  "deliveryMode": 2,
  "correlationID": null,
  "replyTo": null,
  "destination": {
    "io.confluent.connect.jms.Destination": {
      "destinationType": "topic",
      "name": "TD_LNE_GN_SIG_AREA"
    }
  },
  "redelivered": false,
  "type": null,
  "expiration": 1558388811199,
  "priority": 4,
  "properties": {},
  "bytes": null,
  "map": null,
  "text": {
    "string": "[{\"CA_MSG\":{\"to\":\"0477\",\"time\":\"1558388506000\",\"area_id\":\"KX\",\"msg_type\":\"CA\",\"from\":\"0467\",\"descr\":\"9S64\"}},{\"CA_MSG\":{\"to\":\"0651\",\"time\":\"1558388508000\",\"area_id\":\"KX\",\"msg_type\":\"CA\",\"from\":\"0637\",\"descr\":\"9J70\"}},{\"CA_MSG\":{\"to\":\"0778\",\"time\":\"1558388508000\",\"area_id\":\"KX\",\"msg_type\":\"CA\",\"from\":\"0798\",\"descr\":\"4L00\"}},{\"CA_MSG\":{\"to\":\"COUT\",\"time\":\"1558388508000\",\"area_id\":\"PB\",\"msg_type\":\"CA\",\"from\":\"0798\",\"descr\":\"4L00\"}},{\"CT_MSG\":{\"time\":\"1558388508000\",\"area_id\":\"WE\",\"msg_type\":\"CT\",\"report_time\":\"2226\"}},{\"CA_MSG\":{\"to\":\"0418\",\"time\":\"1558388508000\",\"area_id\":\"KX\",\"msg_type\":\"CA\",\"from\":\"0442\",\"descr\":\"1P57\"}},{\"CC_MSG\":{\"to\":\"COUT\",\"time\":\"1558388509000\",\"area_id\":\"SC\",\"msg_type\":\"CC\",\"descr\":\"4Z35\"}},{\"CA_MSG\":{\"to\":\"0770\",\"time\":\"1558388509000\",\"area_id\":\"DR\",\"msg_type\":\"CA\",\"from\":\"0772\",\"descr\":\"4Z35\"}},{\"CC_MSG\":{\"to\":\"COUT\",\"time\":\"1558388509000\",\"area_id\":\"SC\",\"msg_type\":\"CC\",\"descr\":\"4Z35\"}},{\"CA_MSG\":{\"to\":\"2282\",\"time\":\"1558388509000\",\"area_id\":\"DR\",\"msg_type\":\"CA\",\"from\":\"0292\",\"descr\":\"1E29\"}},{\"CA_MSG\":{\"to\":\"COUT\",\"time\":\"1558388509000\",\"area_id\":\"KX\",\"msg_type\":\"CA\",\"from\":\"0798\",\"descr\":\"4L00\"}},{\"CA_MSG\":{\"to\":\"1282\",\"time\":\"1558388510000\",\"area_id\":\"DR\",\"msg_type\":\"CA\",\"from\":\"2282\",\"descr\":\"1E29\"}},{\"CA_MSG\":{\"to\":\"0271\",\"time\":\"1558388510000\",\"area_id\":\"DR\",\"msg_type\":\"CA\",\"from\":\"0245\",\"descr\":\"1N34\"}}]"
  }
}

CREATE STREAM TD_LNE_GN_SIG_AREA_RAW WITH (KAFKA_TOPIC='networkrail_TD_LNE_GN_SIG_AREA', VALUE_FORMAT='AVRO');

ksql> select text from TD_LNE_GN_SIG_AREA_RAW limit 1;
[{"CT_MSG":{"time":"1558387866000","area_id":"WE","msg_type":"CT","report_time":"2215"}},{"CA_MSG":{"to":"0139","time":"1558387866000","area_id":"DR","msg_type":"CA","from":"0137","descr":"1N34"}},{"CA_MSG":{"to":"0513","time":"1558387867000","area_id":"KX","msg_type":"CA","from":"0509","descr":"2V65"}},{"CA_MSG":{"to":"0405","time":"1558387868000","area_id":"KX","msg_type":"CA","from":"0395","descr":"2C64"}},{"CA_MSG":{"to":"0981","time":"1558387869000","area_id":"KX","msg_type":"CA","from":"0977","descr":"2C60"}},{"CA_MSG":{"to":"0473","time":"1558387869000","area_id":"PB","msg_type":"CA","from":"0433","descr":"404D"}},{"CC_MSG":{"to":"0253","time":"1558387872000","area_id":"KX","msg_type":"CC","descr":"9S64"}}]

ksql> select EXTRACTJSONFIELD(text,'$[0]') from TD_LNE_GN_SIG_AREA_RAW limit 1;
{"CT_MSG":{"time":"1558387866000","area_id":"WE","msg_type":"CT","report_time":"2215"}}

request-pipelining ON
-- https://wiki.openraildata.com/index.php?title=NROD_Message_Batching
-- Messages are in batches of up to a limit of 32 per batch
CREATE STREAM TD_LNE_GN_SIG_AREA_EXPLODE_00 AS SELECT EXTRACTJSONFIELD(TEXT,'$[0]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[1]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[2]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[3]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[4]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[5]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[6]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[7]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[8]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[9]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[10]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[11]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[12]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[13]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[14]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[15]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[16]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[17]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[18]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[19]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[20]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[21]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[22]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[23]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[24]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[25]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[26]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[27]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[28]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[29]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[30]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;
INSERT INTO   TD_LNE_GN_SIG_AREA_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[31]') AS MSG_JSON FROM TD_LNE_GN_SIG_AREA_RAW;

Ref: https://wiki.openraildata.com/index.php/TD
Ref: https://wiki.openraildata.com/index.php?title=C_Class_Messages
Ref: https://wiki.openraildata.com/index.php?title=TD_Berths
Ref: https://wiki.openraildata.com/index.php/List_of_Train_Describers

ksql> select * from TD_LNE_GN_SIG_AREA_EXPLODE_00;
1558387884889 | �ID:opendata-backend.rockshore.net-38887-1556015157154-11:11706:3:21:41895 | {"CT_MSG":{"time":"1558387866000","area_id":"WE","msg_type":"CT","report_time":"2215"}}
1558387891199 | �ID:opendata-backend.rockshore.net-38887-1556015157154-11:11706:2:40:48680 | {"CA_MSG":{"to":"0383","time":"1558387874000","area_id":"KX","msg_type":"CA","from":"0373","descr":"2V67"}}
1558387896199 | �ID:opendata-backend.rockshore.net-38887-1556015157154-11:11706:3:21:41896 | {"CA_MSG":{"to":"0393","time":"1558387892000","area_id":"KX","msg_type":"CA","from":"0383","descr":"2V67"}}
1558387914119 | �ID:opendata-backend.rockshore.net-38887-1556015157154-11:11706:2:40:48681 | {"CA_MSG":{"to":"0056","time":"1558387896000","area_id":"DR","msg_type":"CA","from":"0058","descr":"6L84"}}


CREATE STREAM TD_LNE_GN_SIG_AREA_CT_02 WITH (TIMESTAMP='TIMESTAMP_EPOCH') AS
SELECT  EXTRACTJSONFIELD(MSG_JSON,'$.CT_MSG.report_time') AS REPORT_TIME,
        EXTRACTJSONFIELD(MSG_JSON,'$.CT_MSG.area_id') AS AREA_ID, 
        EXTRACTJSONFIELD(MSG_JSON,'$.CT_MSG.msg_type') AS MSG_TYPE, 
        CAST(EXTRACTJSONFIELD(MSG_JSON,'$.CT_MSG.time') AS BIGINT) AS TIMESTAMP_EPOCH
   FROM TD_LNE_GN_SIG_AREA_EXPLODE_00 WHERE EXTRACTJSONFIELD(MSG_JSON,'$.CT_MSG.msg_type') IS NOT NULL;

CREATE STREAM TD_LNE_GN_SIG_AREA_CA_02 WITH (TIMESTAMP='TIMESTAMP_EPOCH') AS
SELECT  EXTRACTJSONFIELD(MSG_JSON,'$.CA_MSG.descr') AS TRAIN_DESCRIPTION,
        EXTRACTJSONFIELD(MSG_JSON,'$.CA_MSG.to') AS BERTH_TO,
        EXTRACTJSONFIELD(MSG_JSON,'$.CA_MSG.from') AS BERTH_FROM,
        EXTRACTJSONFIELD(MSG_JSON,'$.CA_MSG.area_id') AS AREA_ID, 
        EXTRACTJSONFIELD(MSG_JSON,'$.CA_MSG.msg_type') AS MSG_TYPE, 
        CAST(EXTRACTJSONFIELD(MSG_JSON,'$.CA_MSG.time') AS BIGINT) AS TIMESTAMP_EPOCH
   FROM TD_LNE_GN_SIG_AREA_EXPLODE_00 WHERE EXTRACTJSONFIELD(MSG_JSON,'$.CA_MSG.msg_type') IS NOT NULL;

---

curl -i -X POST -H "Accept:application/json" \
    -H  "Content-Type:application/json" http://localhost:8083/connectors/ \
    -d '{
  "name": "source-activemq-networkrail-02",
  "config": {
    "connector.class": "io.confluent.connect.activemq.ActiveMQSourceConnector",
    "activemq.url":"tcp://datafeeds.networkrail.co.uk:61619",
    "activemq.username":"NROD_USERNAME",
    "activemq.password":"NROD_PASSWORD",
    "jms.destination.type":"topic",
    "jms.destination.name":"TD_LNE_GN_SIG_AREA",
    "kafka.topic":"networkrail_TD_LNE_GN_SIG_AREA-02",
    "confluent.license":"",
    "confluent.topic.bootstrap.servers":"kafka:29092",
    "confluent.topic.replication.factor":1, 
    "transforms": "messageField",
    "transforms.messageField.type":"org.apache.kafka.connect.transforms.ExtractField$Value",
    "transforms.messageField.field": "text"
      }
}'

$ docker-compose exec -T kafka-connect \
              kafka-avro-console-consumer \
              --bootstrap-server kafka:29092 \
              --property schema.registry.url=http://schema-registry:8081 \
              --topic networkrail_TD_LNE_GN_SIG_AREA-02 --max-messages 1 | jq -c '.'
"[{\"CA_MSG\":{\"to\":\"0652\",\"time\":\"1558429386000\",\"area_id\":\"KX\",\"msg_type\":\"CA\",\"from\":\"0658\",\"descr\":\"9S19\"}},{\"CA_MSG\":{\"to\":\"0484\",\"time\":\"1558429390000\",\"area_id\":\"KX\",\"msg_type\":\"CA\",\"from\":\"0494\",\"descr\":\"2K50\"}}]"
Processed a total of 1 messages

---

curl -i -X POST -H "Accept:application/json" \
    -H  "Content-Type:application/json" http://localhost:8083/connectors/ \
    -d '{
  "name": "source-activemq-networkrail-03",
  "config": {
    "connector.class": "io.confluent.connect.activemq.ActiveMQSourceConnector",
    "activemq.url":"tcp://datafeeds.networkrail.co.uk:61619",
    "activemq.username":"NROD_USERNAME",
    "activemq.password":"NROD_PASSWORD",
    "jms.destination.type":"topic",
    "jms.destination.name":"TD_LNE_GN_SIG_AREA",
    "kafka.topic":"networkrail_TD_LNE_GN_SIG_AREA-03",
    "confluent.license":"",
    "confluent.topic.bootstrap.servers":"kafka:29092",
    "confluent.topic.replication.factor":1, 
    "transforms": "messageField",
    "transforms.messageField.type":"org.apache.kafka.connect.transforms.ExtractField$Value",
    "transforms.messageField.field": "text",
    "value.converter": "org.apache.kafka.connect.storage.StringConverter"
  }
}'

$ kafkacat -b localhost:9092 -t networkrail_TD_LNE_GN_SIG_AREA-03
% Auto-selecting Consumer mode (use -P or -C to override)
[{"CA_MSG":{"to":"0300","time":"1558429736000","area_id":"DR","msg_type":"CA","from":"0812","descr":"1E02"}},{"CA_MSG":{"to":"0052","time":"1558429740000","area_id":"DR","msg_type":"CA","from":"0056","descr":"1A59"}},{"CC_MSG":{"to":"COUT","time":"1558429740000","area_id":"SC","msg_type":"CC","descr":"2P07"}},{"CA_MSG":{"to":"0606","time":"1558429740000","area_id":"DR","msg_type":"CA","from":"0608","descr":"2P07"}},{"CC_MSG":{"to":"COUT","time":"1558429740000","area_id":"SC","msg_type":"CC","descr":"2P07"}},{"CA_MSG":{"to":"0391","time":"1558429740000","area_id":"PB","msg_type":"CA","from":"0389","descr":"*LB*"}},{"CA_MSG":{"to":"0858","time":"1558429742000","area_id":"DR","msg_type":"CA","from":"0860","descr":"1E03"}}]

ksql> CREATE STREAM TD_LNE_GN_SIG_AREA (DATA ARRAY<VARCHAR>) WITH (KAFKA_TOPIC='networkrail_TD_LNE_GN_SIG_AREA-03', VALUE_FORMAT='JSON');

 Message
----------------
 Stream created
----------------

[2019-05-21 09:17:40,786] WARN task [0_0] Skipping record due to deserialization error. topic=[networkrail_TD_LNE_GN_SIG_AREA-03] partition=[0] offset=[52] (org.apache.kafka.streams.processor.internals.RecordDeserializer:86)
org.apache.kafka.common.errors.SerializationException: KsqlJsonDeserializer failed to deserialize data for topic: networkrail_TD_LNE_GN_SIG_AREA-03
Caused by: java.lang.ClassCastException: java.util.ArrayList cannot be cast to java.util.Map
 at io.confluent.ksql.serde.json.KsqlJsonDeserializer.getGenericRow(KsqlJsonDeserializer.java:93)
 at io.confluent.ksql.serde.json.KsqlJsonDeserializer.deserialize(KsqlJsonDeserializer.java:74)
 at io.confluent.ksql.serde.json.KsqlJsonDeserializer.deserialize(KsqlJsonDeserializer.java:42)
 at org.apache.kafka.common.serialization.Deserializer.deserialize(Deserializer.java:58)




 ----

 https://wiki.openraildata.com/index.php?title=Train_Movements
 https://wiki.openraildata.com/index.php?title=TRUST_Message_Process
 https://wiki.openraildata.com/index.php?title=Train_Movement

 curl -i -X POST -H "Accept:application/json" \
    -H  "Content-Type:application/json" http://localhost:8083/connectors/ \
    -d '{
  "name": "source-activemq-networkrail-TRAIN_MVT_ALL_TOC-00",
  "config": {
    "connector.class": "io.confluent.connect.activemq.ActiveMQSourceConnector",
    "activemq.url":"tcp://datafeeds.networkrail.co.uk:61619",
    "activemq.username":"NROD_USERNAME",
    "activemq.password":"NROD_PASSWORD",
    "jms.destination.type":"topic",
    "jms.destination.name":"TRAIN_MVT_ALL_TOC",
    "kafka.topic":"networkrail_TRAIN_MVT_ALL_TOC",
    "confluent.license":"",
    "confluent.topic.bootstrap.servers":"kafka:29092",
    "confluent.topic.replication.factor":1
  }
}'

curl -i -X POST -H "Accept:application/json" \
-H  "Content-Type:application/json" http://localhost:8083/connectors/ \
-d '{
"name": "source-activemq-networkrail-TRAIN_MVT_EA_TOC-01",
"config": {
"connector.class": "io.confluent.connect.activemq.ActiveMQSourceConnector",
"activemq.url":"tcp://datafeeds.networkrail.co.uk:61619",
"activemq.username":"NROD_USERNAME",
"activemq.password":"NROD_PASSWORD",
"jms.destination.type":"topic",
"jms.destination.name":"TRAIN_MVT_EA_TOC",
"kafka.topic":"networkrail_TRAIN_MVT",
"value.converter": "org.apache.kafka.connect.json.JsonConverter",
"value.converter.schemas.enable": "false",
"key.converter": "org.apache.kafka.connect.json.JsonConverter",
"key.converter.schemas.enable": "false",
"confluent.license":"",
"confluent.topic.bootstrap.servers":"kafka:29092",
"confluent.topic.replication.factor":1
}
}'


curl -i -X POST -H "Accept:application/json" \
-H  "Content-Type:application/json" http://localhost:8083/connectors/ \
-d '{
"name": "source-activemq-networkrail-TRAIN_MVT_ED_TOC-01",
"config": {
"connector.class": "io.confluent.connect.activemq.ActiveMQSourceConnector",
"activemq.url":"tcp://datafeeds.networkrail.co.uk:61619",
"activemq.username":"NROD_USERNAME",
"activemq.password":"NROD_PASSWORD",
"jms.destination.type":"topic",
"jms.destination.name":"TRAIN_MVT_ED_TOC",
"kafka.topic":"networkrail_TRAIN_MVT",
"value.converter": "org.apache.kafka.connect.json.JsonConverter",
"value.converter.schemas.enable": "false",
"key.converter": "org.apache.kafka.connect.json.JsonConverter",
"key.converter.schemas.enable": "false",
"confluent.license":"",
"confluent.topic.bootstrap.servers":"kafka:29092",
"confluent.topic.replication.factor":1
}
}'


CREATE STREAM TRAIN_MVT_EA_TOC_RAW WITH (KAFKA_TOPIC='networkrail_TRAIN_MVT_EA_TOC', VALUE_FORMAT='AVRO');

request-pipelining ON
-- https://wiki.openraildata.com/index.php?title=NROD_Message_Batching
-- Messages are in batches of up to a limit of 32 per batch
CREATE STREAM TRAIN_MVT_EA_TOC_EXPLODE_00 AS SELECT EXTRACTJSONFIELD(TEXT,'$[0]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[1]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[2]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[3]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[4]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[5]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[6]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[7]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[8]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[9]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[10]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[11]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[12]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[13]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[14]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[15]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[16]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[17]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[18]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[19]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[20]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[21]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[22]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[23]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[24]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[25]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[26]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[27]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[28]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[29]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[30]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;
INSERT INTO   TRAIN_MVT_EA_TOC_EXPLODE_00    SELECT EXTRACTJSONFIELD(TEXT,'$[31]') AS MSG_JSON FROM TRAIN_MVT_EA_TOC_RAW;

CREATE STREAM TRAIN_MVT_EA_TOC_MVT_00 WITH (TIMESTAMP='header_msg_queue_timestamp') AS
   SELECT  EXTRACTJSONFIELD(MSG_JSON,'$.header.msg_type') as header_msg_type,
            EXTRACTJSONFIELD(MSG_JSON,'$.header.source_dev_id') as header_source_dev_id,
            EXTRACTJSONFIELD(MSG_JSON,'$.header.user_id') as header_user_id,
            EXTRACTJSONFIELD(MSG_JSON,'$.header.original_data_source') as header_original_data_source,
            CAST(EXTRACTJSONFIELD(MSG_JSON,'$.header.msg_queue_timestamp') AS BIGINT) as header_msg_queue_timestamp,
            EXTRACTJSONFIELD(MSG_JSON,'$.header.source_system_id') as header_source_system_id,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.event_type') as event_type,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.gbtt_timestamp')  as gbtt_timestamp,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.original_loc_stanox') as original_loc_stanox,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.planned_timestamp')  as planned_timestamp,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.timetable_variation') as timetable_variation,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.original_loc_timestamp')  as original_loc_timestamp,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.current_train_id') as current_train_id,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.delay_monitoring_point') as delay_monitoring_point,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.next_report_run_time') as next_report_run_time,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.reporting_stanox') as reporting_stanox,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.actual_timestamp') as actual_timestamp,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.correction_ind') as correction_ind,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.event_source') as event_source,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.train_file_address') as train_file_address,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.platform') as platform,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.division_code') as division_code,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.train_terminated') as train_terminated,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.train_id') as train_id,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.offroute_ind') as offroute_ind,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.variation_status') as variation_status,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.train_service_code') as train_service_code,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.toc_id') as toc_id,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.loc_stanox') as loc_stanox,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.auto_expected') as auto_expected,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.direction_ind') as direction_ind,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.route') as route,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.planned_event_type') as planned_event_type,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.next_report_stanox') as next_report_stanox,
            EXTRACTJSONFIELD(MSG_JSON,'$.body.line_ind') as line_ind
      FROM TRAIN_MVT_EA_TOC_EXPLODE_00 WHERE EXTRACTJSONFIELD(MSG_JSON,'$.header.msg_type') = '0003';

Fields: https://wiki.openraildata.com/index.php?title=Train_Movement

----

Alternative explode method that won't kill KSQL: 

$ kafkacat -b localhost:9092 -t array_example -P <<EOF
[{"col1":"message1"},{"col1":"message2"},{"col1":"message3"}]
EOF

$ kafkacat -b localhost:9092 -t array_example -C -c1 | jq '.'
[
  {
    "col1": "message1"
  },
  {
    "col1": "message2"
  },
  {
    "col1": "message3"
  }
]

$ kafkacat -b localhost:9092 -t array_example -C -c1 | jq -c '.'
[{"col1":"message1"},{"col1":"message2"},{"col1":"message3"}]

$ kafkacat -b localhost:9092 -t array_example -C -c1 | jq -c '.' | wc -l
       1

$ kafkacat -b localhost:9092 -t array_example -C -c1 | jq -c '.[]'
{"col1":"message1"}
{"col1":"message2"}
{"col1":"message3"}

$ kafkacat -b localhost:9092 -t array_example -C -c1 | jq -c '.[]' | wc -l
       3

kafkacat -b localhost:9092 -t array_example -C -u | jq -c '.[]' | kafkacat -b localhost:9092 -t array_exploded -P

----


kafkacat -b localhost:9092 -t networkrail_TRAIN_MVT_EA_TOC_01 -C | jq -c '.text|fromjson[]' | kafkacat -b localhost:9092 -t networkrail_TRAIN_MVT_EA_TOC_01_X -P





== Join movement to location

ksql> SELECT TIMESTAMPTOSTRING(TM.ROWTIME, 'yyyy-MM-dd HH:mm:ss') as MESSAGE_TS, TIMESTAMPTOSTRING(CAST(planned_timestamp AS BIGINT), 'yyyy-MM-dd HH:mm:ss') AS planned_timestamp, TIMESTAMPTOSTRING(CAST(actual_timestamp AS BIGINT),  'yyyy-MM-dd HH:mm:ss') AS actual_timestamp, timetable_variation, EVENT_TYPE, REPORTING_STANOX, LOC_STANOX, S.NLCDESC AS LOC_DESC, NEXT_REPORT_STANOX, PLATFORM, TRAIN_ID, TRAIN_SERVICE_CODE, VARIATION_STATUS FROM TRAIN_MVT_EA_TOC_MVT_00 TM INNER JOIN STANOX S ON TM.LOC_STANOX=S.STANOX LIMIT 5;
2019-05-21 10:50:17 | 2019-05-21 11:43:30 | 2019-05-21 11:49:00 | 6 | DEPARTURE | 00000 | 17112 | CROSS GATES YORKS | 16602 |  1 | 321P21MG21 | 21734000 | LATE
2019-05-21 10:50:41 | 2019-05-21 11:50:30 | 2019-05-21 11:50:00 | 0 | DEPARTURE | 17132 | 17132 | LEEDS | 17131 | 16 | 121P22MG21 | 21731000 | ON TIME
2019-05-21 10:50:41 | 2019-05-21 11:44:30 | 2019-05-21 11:50:00 | 6 | DEPARTURE | 18479 | 18479 | MARSDEN | 18477 |  1 | 322M71MI21 | 21733000 | LATE
2019-05-21 10:51:02 | 2019-05-21 11:49:00 | 2019-05-21 11:51:00 | 2 | DEPARTURE | 18444 | 18444 | HEATON LODGE EAST JN | 18442 |  | 321P71MH21 | 21734000 | LATE
2019-05-21 10:51:16 | 2019-05-21 11:51:00 | 2019-05-21 11:52:00 | 1 | ARRIVAL | 19211 | 19211 | BROUGH | 19215 |  2 | 191K18MJ21 | 21733000 | LATE
Limit Reached
Query terminated



SELECT TIMESTAMPTOSTRING(TM.ROWTIME, 'yyyy-MM-dd HH:mm:ss') as MESSAGE_TS, 
       BODY->EVENT_TYPE, 
       S.NLCDESC AS LOC_DESC, 
       CASE WHEN LEN(BODY->PLATFORM)>0 THEN 'Platform ' + BODY->PLATFORM ELSE '' END AS PLATFORM,
       TIMESTAMPTOSTRING(CAST(BODY->planned_timestamp AS BIGINT), 'yyyy-MM-dd HH:mm:ss') AS planned_timestamp, 
       TIMESTAMPTOSTRING(CAST(BODY->actual_timestamp AS BIGINT),  'yyyy-MM-dd HH:mm:ss') AS actual_timestamp, 
       BODY->TIMETABLE_VARIATION, 
       BODY->VARIATION_STATUS, 
       BODY->TOC_ID,
       BODY->TRAIN_ID, 
       BODY->TRAIN_SERVICE_CODE
  FROM TRAIN_MVT_EA_TOC_MVT_01_X TM 
        INNER JOIN STANOX S 
        ON TM.BODY->LOC_STANOX=S.STANOX LIMIT 5;

Caused by:  Line: 14, Col: 31 : Invalid join criteria (TM.BODY->LOC_STANOX =
        S.STANOX). Could not find a join criteria operand for TM.

-- CREATE STREAM TRAIN_MVT_EA_TOC_MVT_01_X_FLAT WITH (VALUE_FORMAT='AVRO') AS 
-- SELECT  HEADER->MSG_TYPE  AS MSG_TYPE ,
--         HEADER->SOURCE_DEV_ID  AS SOURCE_DEV_ID ,
--         HEADER->USER_ID  AS USER_ID ,
--         HEADER->ORIGINAL_DATA_SOURCE  AS ORIGINAL_DATA_SOURCE ,
--         HEADER->MSG_QUEUE_TIMESTAMP  AS MSG_QUEUE_TIMESTAMP ,
--         HEADER->SOURCE_SYSTEM_ID  AS SOURCE_SYSTEM_ID ,
--         BODY->EVENT_TYPE  AS EVENT_TYPE ,
--         BODY->GBTT_TIMESTAMP  AS GBTT_TIMESTAMP ,
--         BODY->ORIGINAL_LOC_STANOX  AS ORIGINAL_LOC_STANOX ,
--         BODY->PLANNED_TIMESTAMP  AS PLANNED_TIMESTAMP ,
--         BODY->TIMETABLE_VARIATION  AS TIMETABLE_VARIATION ,
--         BODY->ORIGINAL_LOC_TIMESTAMP  AS ORIGINAL_LOC_TIMESTAMP ,
--         BODY->CURRENT_TRAIN_ID  AS CURRENT_TRAIN_ID ,
--         BODY->DELAY_MONITORING_POINT  AS DELAY_MONITORING_POINT ,
--         BODY->NEXT_REPORT_RUN_TIME  AS NEXT_REPORT_RUN_TIME ,
--         BODY->REPORTING_STANOX  AS REPORTING_STANOX ,
--         BODY->ACTUAL_TIMESTAMP  AS ACTUAL_TIMESTAMP ,
--         BODY->CORRECTION_IND  AS CORRECTION_IND ,
--         BODY->EVENT_SOURCE  AS EVENT_SOURCE ,
--         BODY->TRAIN_FILE_ADDRESS  AS TRAIN_FILE_ADDRESS ,
--         BODY->PLATFORM  AS PLATFORM ,
--         BODY->DIVISION_CODE  AS DIVISION_CODE ,
--         BODY->TRAIN_TERMINATED  AS TRAIN_TERMINATED ,
--         BODY->TRAIN_ID  AS TRAIN_ID ,
--         BODY->OFFROUTE_IND  AS OFFROUTE_IND ,
--         BODY->VARIATION_STATUS  AS VARIATION_STATUS ,
--         BODY->TRAIN_SERVICE_CODE  AS TRAIN_SERVICE_CODE ,
--         BODY->TOC_ID  AS TOC_ID ,
--         BODY->LOC_STANOX  AS LOC_STANOX ,
--         BODY->AUTO_EXPECTED  AS AUTO_EXPECTED ,
--         BODY->DIRECTION_IND  AS DIRECTION_IND ,
--         BODY->ROUTE  AS ROUTE ,
--         BODY->PLANNED_EVENT_TYPE  AS PLANNED_EVENT_TYPE ,
--         BODY->NEXT_REPORT_STANOX  AS NEXT_REPORT_STANOX ,
--         BODY->LINE_IND  AS LINE_IND 
-- FROM TRAIN_MVT_EA_TOC_MVT_01_X;


CREATE STREAM TRAIN_MOVEMENTS_WITH_STANOX WITH (VALUE_FORMAT='AVRO') AS 
SELECT TIMESTAMPTOSTRING(TM.ROWTIME, 'yyyy-MM-dd HH:mm:ss') as MESSAGE_TS, 
       EVENT_TYPE, 
       S.NLCDESC AS LOC_DESC, 
       CASE WHEN LEN(PLATFORM)>0 THEN 'Platform ' + PLATFORM ELSE '' END AS PLATFORM,
       TIMESTAMPTOSTRING(CAST(planned_timestamp AS BIGINT), 'yyyy-MM-dd HH:mm:ss') AS planned_timestamp, 
       TIMESTAMPTOSTRING(CAST(actual_timestamp AS BIGINT),  'yyyy-MM-dd HH:mm:ss') AS actual_timestamp, 
       TIMETABLE_VARIATION, 
       VARIATION_STATUS, 
       TOC_ID,
       TRAIN_ID, 
       TRAIN_SERVICE_CODE
  FROM TRAIN_MOVEMENTS TM 
        INNER JOIN STANOX S 
        ON TM.LOC_STANOX=S.STANOX;



=== Join movement to activations

SELECT * FROM TRAIN_MOVEMENTS_WITH_STANOX TMS INNER JOIN TRAIN_ACTIVATIONS_00 TA WITHIN 4 HOURS ON TMS.TRAIN_ID = TA.TRAIN_ID LIMIT 1;

-> join ta.sched_origin_stanox to stanox to get the train's origin
-> is there anything useful to be done with schedule data? 